{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b404c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% [Block 0: Imports & Setup]\n",
    "import os, json, math, warnings, logging, sys\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85dadaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-03 08:00:10,853 | INFO | Environment initialized. XGBoost available: True\n"
     ]
    }
   ],
   "source": [
    "# Optional: XGBoost (guarded import)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# Logging setup (console + file)\n",
    "LOG_DIR = \"ml_artifacts\"\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "logfile = os.path.join(LOG_DIR, f\"k2_train_{datetime.now().strftime('%Y%m%d-%H%M%S')}.log\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(stream=sys.stdout), \n",
    "        logging.FileHandler(logfile, encoding=\"utf-8\")\n",
    "    ],\n",
    "    force=True, \n",
    ")\n",
    "log = logging.getLogger(\"K2-Exo\")\n",
    "log.info(\"Environment initialized. XGBoost available: %s\", HAS_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21d9b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% [Block 1: Config]\n",
    "CSV_PATH = r\"E:\\Nasa Space App 2025\\Hunting_For_Exoplanets_With_AI_Nasa2025\\DataSet\\K2\\K2_train.csv\"\n",
    "SELECT_K = 40  # initial cap; will be validated after preprocessing fit\n",
    "MIN_ONEHOT_FREQ = 10  # to constrain OHE explosion\n",
    "TEST_SIZE = 0.2\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "LABEL_SET = [\"CANDIDATE\", \"CONFIRMED\", \"FALSE POSITIVE\"]\n",
    "LABEL_TO_ID = {lab: i for i, lab in enumerate(LABEL_SET)}\n",
    "ID_TO_LABEL = {v: k for k, v in LABEL_TO_ID.items()}\n",
    "\n",
    "ARTIFACT_PREFIX = \"k2_exo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630dead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% [Block 2: Utility functions]\n",
    "def json_safe(x):\n",
    "    \"\"\"Make common numpy/scikit objects JSON serializable.\"\"\"\n",
    "    if isinstance(x, np.generic):\n",
    "        return x.item()\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.tolist()\n",
    "    if isinstance(x, dict):\n",
    "        return {k: json_safe(v) for k, v in x.items()}\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return [json_safe(v) for v in x]\n",
    "    return x\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title, save_path=None):\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", colorbar=False)\n",
    "    ax.set_title(title, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4312cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-03 08:01:02,321 | INFO | Loading CSV from E:\\Nasa Space App 2025\\Hunting_For_Exoplanets_With_AI_Nasa2025\\DataSet\\K2\\K2_train.csv\n",
      "2025-10-03 08:01:02,461 | INFO | Class distribution: {'CONFIRMED': 2208, 'CANDIDATE': 1369, 'FALSE POSITIVE': 293}\n"
     ]
    }
   ],
   "source": [
    "#%% [Block 3: Load & normalize labels]\n",
    "log.info(\"Loading CSV from %s\", CSV_PATH)\n",
    "df = pd.read_csv(CSV_PATH, comment=\"#\", low_memory=False)\n",
    "\n",
    "df[\"disposition_norm\"] = (\n",
    "    df[\"disposition\"].astype(str).str.strip().str.upper().str.replace(\"_\", \" \")\n",
    ")\n",
    "df = df[df[\"disposition_norm\"].isin(LABEL_SET)].copy()\n",
    "df[\"y\"] = df[\"disposition_norm\"].map(LABEL_TO_ID).astype(int)\n",
    "\n",
    "class_counts = df[\"disposition_norm\"].value_counts().to_dict()\n",
    "log.info(\"Class distribution: %s\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92067a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl_name</th>\n",
       "      <th>hostname</th>\n",
       "      <th>default_flag</th>\n",
       "      <th>disposition</th>\n",
       "      <th>disp_refname</th>\n",
       "      <th>sy_snum</th>\n",
       "      <th>sy_pnum</th>\n",
       "      <th>discoverymethod</th>\n",
       "      <th>disc_year</th>\n",
       "      <th>disc_facility</th>\n",
       "      <th>...</th>\n",
       "      <th>sy_kmagerr1</th>\n",
       "      <th>sy_kmagerr2</th>\n",
       "      <th>sy_gaiamag</th>\n",
       "      <th>sy_gaiamagerr1</th>\n",
       "      <th>sy_gaiamagerr2</th>\n",
       "      <th>rowupdate</th>\n",
       "      <th>pl_pubdate</th>\n",
       "      <th>releasedate</th>\n",
       "      <th>disposition_norm</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BD+20 594 b</td>\n",
       "      <td>BD+20 594</td>\n",
       "      <td>0</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>Espinoza et al. 2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>10.8644</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>2018-03</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BD+20 594 b</td>\n",
       "      <td>BD+20 594</td>\n",
       "      <td>0</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>Espinoza et al. 2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>10.8644</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-07-28</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BD+20 594 b</td>\n",
       "      <td>BD+20 594</td>\n",
       "      <td>1</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>Espinoza et al. 2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>10.8644</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>2018-04-26</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPIC 201111557.01</td>\n",
       "      <td>EPIC 201111557</td>\n",
       "      <td>0</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>Livingston et al. 2018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>11.3995</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>-0.001307</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>2018-03</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPIC 201111557.01</td>\n",
       "      <td>EPIC 201111557</td>\n",
       "      <td>1</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>Livingston et al. 2018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>11.3995</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>-0.001307</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>2018-08</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EPIC 201126503.01</td>\n",
       "      <td>EPIC 201126503</td>\n",
       "      <td>1</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>Vanderburg et al. 2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>17.8892</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>-0.001662</td>\n",
       "      <td>2015-12-05</td>\n",
       "      <td>2016-01</td>\n",
       "      <td>2015-12-05</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EPIC 201127519.01</td>\n",
       "      <td>EPIC 201127519</td>\n",
       "      <td>0</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>Livingston et al. 2018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>11.4806</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>2018-03</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EPIC 201127519.01</td>\n",
       "      <td>EPIC 201127519</td>\n",
       "      <td>1</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>Livingston et al. 2018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>11.4806</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>2018-08</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EPIC 201147085.01</td>\n",
       "      <td>EPIC 201147085</td>\n",
       "      <td>1</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>Kruse et al. 2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EPIC 201152065.01</td>\n",
       "      <td>EPIC 201152065</td>\n",
       "      <td>1</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>Kruse et al. 2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>13.9562</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pl_name        hostname  default_flag disposition  \\\n",
       "0        BD+20 594 b       BD+20 594             0   CONFIRMED   \n",
       "1        BD+20 594 b       BD+20 594             0   CONFIRMED   \n",
       "2        BD+20 594 b       BD+20 594             1   CONFIRMED   \n",
       "3  EPIC 201111557.01  EPIC 201111557             0   CANDIDATE   \n",
       "4  EPIC 201111557.01  EPIC 201111557             1   CANDIDATE   \n",
       "5  EPIC 201126503.01  EPIC 201126503             1   CANDIDATE   \n",
       "6  EPIC 201127519.01  EPIC 201127519             0   CANDIDATE   \n",
       "7  EPIC 201127519.01  EPIC 201127519             1   CANDIDATE   \n",
       "8  EPIC 201147085.01  EPIC 201147085             1   CANDIDATE   \n",
       "9  EPIC 201152065.01  EPIC 201152065             1   CANDIDATE   \n",
       "\n",
       "             disp_refname  sy_snum  sy_pnum discoverymethod  disc_year  \\\n",
       "0    Espinoza et al. 2016      1.0      1.0         Transit     2016.0   \n",
       "1    Espinoza et al. 2016      1.0      1.0         Transit     2016.0   \n",
       "2    Espinoza et al. 2016      1.0      1.0         Transit     2016.0   \n",
       "3  Livingston et al. 2018      1.0      0.0         Transit     2018.0   \n",
       "4  Livingston et al. 2018      1.0      0.0         Transit     2018.0   \n",
       "5  Vanderburg et al. 2016      1.0      0.0         Transit     2016.0   \n",
       "6  Livingston et al. 2018      1.0      0.0         Transit     2018.0   \n",
       "7  Livingston et al. 2018      1.0      0.0         Transit     2018.0   \n",
       "8       Kruse et al. 2019      1.0      0.0         Transit     2019.0   \n",
       "9       Kruse et al. 2019      1.0      0.0         Transit     2019.0   \n",
       "\n",
       "  disc_facility  ... sy_kmagerr1  sy_kmagerr2 sy_gaiamag  sy_gaiamagerr1  \\\n",
       "0            K2  ...       0.018       -0.018    10.8644        0.000249   \n",
       "1            K2  ...       0.018       -0.018    10.8644        0.000249   \n",
       "2            K2  ...       0.018       -0.018    10.8644        0.000249   \n",
       "3            K2  ...       0.019       -0.019    11.3995        0.001307   \n",
       "4            K2  ...       0.019       -0.019    11.3995        0.001307   \n",
       "5            K2  ...       0.070       -0.070    17.8892        0.001662   \n",
       "6            K2  ...       0.021       -0.021    11.4806        0.000478   \n",
       "7            K2  ...       0.021       -0.021    11.4806        0.000478   \n",
       "8            K2  ...       0.023       -0.023        NaN             NaN   \n",
       "9            K2  ...       0.023       -0.023    13.9562        0.000535   \n",
       "\n",
       "   sy_gaiamagerr2   rowupdate  pl_pubdate  releasedate  disposition_norm  y  \n",
       "0       -0.000249  2018-04-25     2018-03   2018-02-15         CONFIRMED  1  \n",
       "1       -0.000249  2018-04-25     2016-10   2016-07-28         CONFIRMED  1  \n",
       "2       -0.000249  2018-04-25     2017-03   2018-04-26         CONFIRMED  1  \n",
       "3       -0.001307  2018-02-15     2018-03   2018-02-15         CANDIDATE  0  \n",
       "4       -0.001307  2018-08-02     2018-08   2018-08-02         CANDIDATE  0  \n",
       "5       -0.001662  2015-12-05     2016-01   2015-12-05         CANDIDATE  0  \n",
       "6       -0.000478  2018-02-15     2018-03   2018-02-15         CANDIDATE  0  \n",
       "7       -0.000478  2018-08-02     2018-08   2018-08-02         CANDIDATE  0  \n",
       "8             NaN  2019-09-05     2019-09   2019-09-05         CANDIDATE  0  \n",
       "9       -0.000535  2019-09-05     2019-09   2019-09-05         CANDIDATE  0  \n",
       "\n",
       "[10 rows x 96 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99513cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-03 08:01:33,734 | INFO | Feature engineering complete. Current columns: 104\n"
     ]
    }
   ],
   "source": [
    "#%% [Block 4: Feature engineering]\n",
    "def add_k2_features(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = frame.copy()\n",
    "    if {\"pl_rade\",\"pl_radj\"}.issubset(out.columns):\n",
    "        denom = (out[\"pl_radj\"] * 11.209).replace(0, np.nan)\n",
    "        out[\"radius_consistency\"] = out[\"pl_rade\"] / denom\n",
    "    if {\"pl_bmasse\",\"pl_rade\"}.issubset(out.columns):\n",
    "        denom = (out[\"pl_rade\"]**3).replace(0, np.nan)\n",
    "        out[\"bulk_density_proxy\"] = out[\"pl_bmasse\"] / denom\n",
    "    if {\"pl_orbper\",\"pl_orbsmax\"}.issubset(out.columns):\n",
    "        denom = (out[\"pl_orbsmax\"]**3).replace(0, np.nan)\n",
    "        out[\"kepler_ratio\"] = (out[\"pl_orbper\"]**2) / denom\n",
    "    if {\"pl_eqt\",\"st_teff\"}.issubset(out.columns):\n",
    "        denom = out[\"st_teff\"].replace(0, np.nan)\n",
    "        out[\"temp_ratio\"] = out[\"pl_eqt\"] / denom\n",
    "    if \"pl_insol\" in out.columns:\n",
    "        out[\"log_insol\"] = np.log10(out[\"pl_insol\"].clip(lower=0) + 1)\n",
    "    if {\"st_mass\",\"st_rad\"}.issubset(out.columns):\n",
    "        denom = (out[\"st_rad\"]**3).replace(0, np.nan)\n",
    "        out[\"stellar_density_proxy\"] = out[\"st_mass\"] / denom\n",
    "    if \"sy_dist\" in out.columns:\n",
    "        out[\"log_distance\"] = np.log10(out[\"sy_dist\"].clip(lower=0) + 1)\n",
    "    if \"pl_orbper\" in out.columns:\n",
    "        out[\"log_period\"] = np.log10(out[\"pl_orbper\"].clip(lower=0) + 1)\n",
    "    return out.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "df = add_k2_features(df)\n",
    "log.info(\"Feature engineering complete. Current columns: %d\", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45edae8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-03 08:01:40,406 | INFO | Numeric features: 34 | Categorical: 4\n"
     ]
    }
   ],
   "source": [
    "#%% [Block 5: Feature lists & grouping]\n",
    "base_numeric = [\n",
    "    'sy_snum','sy_pnum','pl_orbper','pl_orbsmax','pl_rade','pl_radj','pl_bmasse','pl_bmassj',\n",
    "    'pl_orbeccen','pl_insol','pl_eqt','st_teff','st_rad','st_mass','st_met','st_logg',\n",
    "    'ra','dec','sy_dist','sy_vmag','sy_kmag','sy_gaiamag',\n",
    "    'radius_consistency','bulk_density_proxy','kepler_ratio','temp_ratio',\n",
    "    'log_insol','stellar_density_proxy','log_distance','log_period'\n",
    "]\n",
    "context_num = [c for c in [\"default_flag\",\"pl_controv_flag\",\"ttv_flag\",\"disc_year\"] if c in df.columns]\n",
    "context_cat = [c for c in [\"discoverymethod\",\"disc_facility\",\"st_spectype\",\"pl_bmassprov\"] if c in df.columns]\n",
    "\n",
    "numeric_features = [c for c in base_numeric + context_num if c in df.columns]\n",
    "categorical_features = [c for c in context_cat if c in df.columns]\n",
    "\n",
    "if \"hostname\" in df.columns:\n",
    "    groups = df[\"hostname\"].astype(str).values\n",
    "else:\n",
    "    ra_bin = (df[\"ra\"]*1000).round().astype(\"Int64\") if \"ra\" in df.columns else 0\n",
    "    dec_bin = (df[\"dec\"]*1000).round().astype(\"Int64\") if \"dec\" in df.columns else 0\n",
    "    groups = (ra_bin.astype(str) + \"_\" + dec_bin.astype(str)).values\n",
    "\n",
    "X_all = df[numeric_features + categorical_features].copy()\n",
    "y_all = df[\"y\"].values\n",
    "\n",
    "log.info(\"Numeric features: %d | Categorical: %d\", len(numeric_features), len(categorical_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680920b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-02 17:06:05,066 | INFO | Split done. Train: 3071 | Test: 799\n"
     ]
    }
   ],
   "source": [
    "#%% [Block 6: Group-aware train/test split]\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "train_idx, test_idx = next(gss.split(X_all, y_all, groups=groups))\n",
    "X_train, X_test = X_all.iloc[train_idx].copy(), X_all.iloc[test_idx].copy()\n",
    "y_train, y_test = y_all[train_idx], y_all[test_idx]\n",
    "groups_train, groups_test = groups[train_idx], groups[test_idx]\n",
    "\n",
    "log.info(\"Split done. Train: %d | Test: %d\", X_train.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff93cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-02 17:06:08,627 | INFO | Class weights: {np.int64(1): 0.5879762588550641, np.int64(0): 0.9434715821812596, np.int64(2): 4.178231292517006}\n"
     ]
    }
   ],
   "source": [
    "#%% [Block 7: Preprocessing & class weights]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\", StandardScaler(with_mean=True, with_std=True))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", min_frequency=MIN_ONEHOT_FREQ))\n",
    "])\n",
    "\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "counts = Counter(y_train)\n",
    "n_classes = len(set(y_train))\n",
    "total = sum(counts.values())\n",
    "class_weight = {cls: total/(n_classes*cnt) for cls, cnt in counts.items()}\n",
    "log.info(\"Class weights: %s\", class_weight)\n",
    "\n",
    "# Helper to build a safe k for SelectKBest after we know feature count\n",
    "def make_select_k(k_cap, preprocessor, X_sample):\n",
    "    # Fit a small preprocessor to get transformed feature count\n",
    "    Z = preprocessor.fit_transform(X_sample.iloc[:200].copy())  # sample for speed\n",
    "    feat_count = Z.shape[1]\n",
    "    k = min(max(10, k_cap), feat_count)  # ensure 10 <= k <= feat_count\n",
    "    log.info(\"SelectKBest | Transformed features=%d | Using k=%d\", feat_count, k)\n",
    "    return SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "\n",
    "def print_progress_block(model_name, acc, cv_mean, cv_std, auc_macro, report_text, cm_array):\n",
    "    line = \"â”€\" * 72\n",
    "    print(f\"\\nðŸ¤– Block 8: Pipelines & Evaluation (Multiclass)\\n\")\n",
    "    print(\"\\nâœ… Results\")\n",
    "    print(f\"   ðŸŽ¯ Accuracy                : {acc:.4f}\")\n",
    "    print(f\"   ðŸ“Š CV F1-macro (train-only): {cv_mean:.4f} (+/- {cv_std:.4f})\")\n",
    "    print(f\"   ðŸ“ˆ ROC AUC (OVR, macro)    : {auc_macro if auc_macro is not None else 'N/A'}\")\n",
    "    print(\"\\n   ðŸ§¾ Per-class report:\")\n",
    "    print(report_text)\n",
    "    print(\"\\n   ðŸ”¢ Confusion matrix:\")\n",
    "    print(np.array(cm_array))\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f3f5145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-02 17:06:20,537 | INFO | SelectKBest | Transformed features=39 | Using k=39\n",
      "2025-10-02 17:06:20,591 | INFO | SelectKBest | Transformed features=39 | Using k=39\n",
      "2025-10-02 17:06:20,645 | INFO | SelectKBest | Transformed features=39 | Using k=39\n",
      "2025-10-02 17:06:20,748 | INFO | SelectKBest | Transformed features=39 | Using k=39\n",
      "2025-10-02 17:06:20,794 | INFO | SelectKBest | Transformed features=39 | Using k=39\n",
      "\n",
      "ðŸ”„ Training Random Forest...\n",
      "\n",
      "ðŸ¤– Block 8: Pipelines & Evaluation (Multiclass)\n",
      "\n",
      "\n",
      "âœ… Results\n",
      "   ðŸŽ¯ Accuracy                : 0.9599\n",
      "   ðŸ“Š CV F1-macro (train-only): 0.8667 (+/- 0.1011)\n",
      "   ðŸ“ˆ ROC AUC (OVR, macro)    : 0.9906940340289453\n",
      "\n",
      "   ðŸ§¾ Per-class report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.93      0.95      0.94       284\n",
      "     CONFIRMED       0.99      1.00      0.99       467\n",
      "FALSE POSITIVE       0.78      0.60      0.68        48\n",
      "\n",
      "      accuracy                           0.96       799\n",
      "     macro avg       0.90      0.85      0.87       799\n",
      "  weighted avg       0.96      0.96      0.96       799\n",
      "\n",
      "\n",
      "   ðŸ”¢ Confusion matrix:\n",
      "[[271   5   8]\n",
      " [  0 467   0]\n",
      " [ 19   0  29]]\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ðŸ”„ Training Gradient Boosting...\n",
      "\n",
      "ðŸ¤– Block 8: Pipelines & Evaluation (Multiclass)\n",
      "\n",
      "\n",
      "âœ… Results\n",
      "   ðŸŽ¯ Accuracy                : 0.9537\n",
      "   ðŸ“Š CV F1-macro (train-only): 0.8556 (+/- 0.1026)\n",
      "   ðŸ“ˆ ROC AUC (OVR, macro)    : 0.9855178164711943\n",
      "\n",
      "   ðŸ§¾ Per-class report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.94      0.93      0.93       284\n",
      "     CONFIRMED       0.99      1.00      0.99       467\n",
      "FALSE POSITIVE       0.70      0.62      0.66        48\n",
      "\n",
      "      accuracy                           0.95       799\n",
      "     macro avg       0.87      0.85      0.86       799\n",
      "  weighted avg       0.95      0.95      0.95       799\n",
      "\n",
      "\n",
      "   ðŸ”¢ Confusion matrix:\n",
      "[[265   6  13]\n",
      " [  0 467   0]\n",
      " [ 18   0  30]]\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ðŸ”„ Training Logistic Regression...\n",
      "\n",
      "ðŸ¤– Block 8: Pipelines & Evaluation (Multiclass)\n",
      "\n",
      "\n",
      "âœ… Results\n",
      "   ðŸŽ¯ Accuracy                : 0.8711\n",
      "   ðŸ“Š CV F1-macro (train-only): 0.7476 (+/- 0.0335)\n",
      "   ðŸ“ˆ ROC AUC (OVR, macro)    : 0.9628437757074527\n",
      "\n",
      "   ðŸ§¾ Per-class report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.95      0.67      0.79       284\n",
      "     CONFIRMED       0.98      1.00      0.99       467\n",
      "FALSE POSITIVE       0.31      0.79      0.44        48\n",
      "\n",
      "      accuracy                           0.87       799\n",
      "     macro avg       0.75      0.82      0.74       799\n",
      "  weighted avg       0.93      0.87      0.89       799\n",
      "\n",
      "\n",
      "   ðŸ”¢ Confusion matrix:\n",
      "[[191   8  85]\n",
      " [  0 467   0]\n",
      " [ 10   0  38]]\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ðŸ”„ Training SVM...\n",
      "\n",
      "ðŸ¤– Block 8: Pipelines & Evaluation (Multiclass)\n",
      "\n",
      "\n",
      "âœ… Results\n",
      "   ðŸŽ¯ Accuracy                : 0.9086\n",
      "   ðŸ“Š CV F1-macro (train-only): 0.7894 (+/- 0.0497)\n",
      "   ðŸ“ˆ ROC AUC (OVR, macro)    : 0.9740274638639664\n",
      "\n",
      "   ðŸ§¾ Per-class report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.96      0.77      0.86       284\n",
      "     CONFIRMED       0.98      1.00      0.99       467\n",
      "FALSE POSITIVE       0.42      0.81      0.55        48\n",
      "\n",
      "      accuracy                           0.91       799\n",
      "     macro avg       0.79      0.86      0.80       799\n",
      "  weighted avg       0.94      0.91      0.92       799\n",
      "\n",
      "\n",
      "   ðŸ”¢ Confusion matrix:\n",
      "[[220  10  54]\n",
      " [  0 467   0]\n",
      " [  9   0  39]]\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ðŸ”„ Training XGBoost...\n",
      "\n",
      "ðŸ¤– Block 8: Pipelines & Evaluation (Multiclass)\n",
      "\n",
      "\n",
      "âœ… Results\n",
      "   ðŸŽ¯ Accuracy                : 0.9587\n",
      "   ðŸ“Š CV F1-macro (train-only): 0.8812 (+/- 0.1128)\n",
      "   ðŸ“ˆ ROC AUC (OVR, macro)    : 0.9895568974049199\n",
      "\n",
      "   ðŸ§¾ Per-class report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.94      0.95      0.94       284\n",
      "     CONFIRMED       0.99      1.00      1.00       467\n",
      "FALSE POSITIVE       0.71      0.62      0.67        48\n",
      "\n",
      "      accuracy                           0.96       799\n",
      "     macro avg       0.88      0.86      0.87       799\n",
      "  weighted avg       0.96      0.96      0.96       799\n",
      "\n",
      "\n",
      "   ðŸ”¢ Confusion matrix:\n",
      "[[269   3  12]\n",
      " [  0 467   0]\n",
      " [ 18   0  30]]\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "2025-10-02 17:07:19,639 | INFO | Block 9: Model Comparison and Best Model Selection\n",
      "\n",
      "=== Model Comparison ===\n",
      "              Model  Test Accuracy  CV F1-macro (mean)  CV F1-macro (Â±2Ïƒ)  ROC AUC (OVR, macro)\n",
      "            XGBoost         0.9587              0.8812             0.1128                0.9896\n",
      "      Random Forest         0.9599              0.8667             0.1011                0.9907\n",
      "  Gradient Boosting         0.9537              0.8556             0.1026                0.9855\n",
      "                SVM         0.9086              0.7894             0.0497                0.9740\n",
      "Logistic Regression         0.8711              0.7476             0.0335                0.9628\n",
      "\n",
      "ðŸ† Best Model: XGBoost\n",
      "   CV F1-macro (mean): 0.8812\n",
      "   Test Accuracy      : 0.9587\n",
      "   ROC AUC (OVR, macro): 0.9895568974049199\n",
      "\n",
      "Detailed Classification Report for XGBoost:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.94      0.95      0.94       284\n",
      "     CONFIRMED       0.99      1.00      1.00       467\n",
      "FALSE POSITIVE       0.71      0.62      0.67        48\n",
      "\n",
      "      accuracy                           0.96       799\n",
      "     macro avg       0.88      0.86      0.87       799\n",
      "  weighted avg       0.96      0.96      0.96       799\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-02 17:07:21,031 | INFO | Block 10: Model Optimization via GridSearchCV (XGBoost)\n"
     ]
    }
   ],
   "source": [
    "#%% [Block 8: Model pipelines & training â€” Pretty Progress Printing]\n",
    "from sklearn.base import clone\n",
    "\n",
    "def make_pipe(clf):\n",
    "    return Pipeline([\n",
    "        (\"pre\", preproc),\n",
    "        (\"sel\", make_select_k(SELECT_K, preproc, X_train)),\n",
    "        (\"clf\", clf)\n",
    "    ])\n",
    "\n",
    "models = {}\n",
    "\n",
    "models[\"Random Forest\"] = make_pipe(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=500, random_state=RANDOM_STATE, n_jobs=-1,\n",
    "        class_weight=\"balanced_subsample\", verbose=0\n",
    "    )\n",
    ")\n",
    "\n",
    "models[\"Gradient Boosting\"] = make_pipe(\n",
    "    GradientBoostingClassifier(random_state=RANDOM_STATE, verbose=0)\n",
    ")\n",
    "\n",
    "models[\"Logistic Regression\"] = make_pipe(\n",
    "    LogisticRegression(\n",
    "        random_state=RANDOM_STATE, max_iter=4000,\n",
    "        class_weight=class_weight, multi_class=\"auto\", solver=\"lbfgs\"\n",
    "    )\n",
    ")\n",
    "\n",
    "models[\"SVM\"] = make_pipe(\n",
    "    SVC(\n",
    "        random_state=RANDOM_STATE, probability=True,\n",
    "        class_weight=class_weight, kernel=\"rbf\", gamma=\"scale\", verbose=False\n",
    "    )\n",
    ")\n",
    "\n",
    "if HAS_XGB:\n",
    "    models[\"XGBoost\"] = make_pipe(\n",
    "        XGBClassifier(\n",
    "            random_state=RANDOM_STATE, n_estimators=600, learning_rate=0.05, max_depth=6,\n",
    "            subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,\n",
    "            objective=\"multi:softprob\", eval_metric=\"mlogloss\", n_jobs=-1,\n",
    "            verbosity=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "gkf = GroupKFold(n_splits=N_SPLITS)\n",
    "results = {}\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    print(f\"\\nðŸ”„ Training {name}...\")\n",
    "    # Grouped CV: F1-macro\n",
    "    cv_scores = cross_val_score(\n",
    "        pipe,\n",
    "        X_train, y_train,\n",
    "        cv=gkf.split(X_train, y_train, groups=groups_train),\n",
    "        scoring=\"f1_macro\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    cv_mean = float(cv_scores.mean())\n",
    "    cv_std = float(cv_scores.std())\n",
    "\n",
    "    # Fit on full train\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Test predictions\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    # AUC (macro OVR)\n",
    "    auc_macro = None\n",
    "    try:\n",
    "        if hasattr(pipe, \"predict_proba\"):\n",
    "            proba = pipe.predict_proba(X_test)\n",
    "            if isinstance(proba, np.ndarray) and proba.ndim == 2:\n",
    "                auc_macro = float(roc_auc_score(y_test, proba, multi_class=\"ovr\", average=\"macro\"))\n",
    "        elif hasattr(pipe, \"decision_function\"):\n",
    "            s = pipe.decision_function(X_test)\n",
    "            if isinstance(s, np.ndarray) and s.ndim == 2:\n",
    "                auc_macro = float(roc_auc_score(y_test, s, multi_class=\"ovr\", average=\"macro\"))\n",
    "    except Exception:\n",
    "        auc_macro = None\n",
    "\n",
    "    acc = float((y_pred == y_test).mean())\n",
    "    f1m = float(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    report_txt = classification_report(y_test, y_pred, target_names=LABEL_SET)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Pretty progress print (exact style you showed)\n",
    "    print_progress_block(\n",
    "        model_name=name,\n",
    "        acc=acc,\n",
    "        cv_mean=cv_mean,\n",
    "        cv_std=2*cv_std,  # print Â±2Ïƒ like your example\n",
    "        auc_macro=auc_macro,\n",
    "        report_text=report_txt,\n",
    "        cm_array=cm\n",
    "    )\n",
    "\n",
    "    # Keep results for later blocks\n",
    "    results[name] = {\n",
    "        \"pipeline\": pipe,\n",
    "        \"accuracy\": acc,\n",
    "        \"f1_macro\": f1m,\n",
    "        \"cv_f1_macro\": cv_mean,\n",
    "        \"cv_f1_macro_std\": cv_std,\n",
    "        \"auc_macro_ovr\": auc_macro,\n",
    "        \"cm\": cm.tolist()\n",
    "    }\n",
    "\n",
    "\n",
    "#%% [Block 9: Model Comparison & Best Selection]\n",
    "log.info(\"Block 9: Model Comparison and Best Model Selection\")\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Model\": list(results.keys()),\n",
    "    \"Test Accuracy\": [v[\"accuracy\"] for v in results.values()],\n",
    "    \"CV F1-macro (mean)\": [v[\"cv_f1_macro\"] for v in results.values()],\n",
    "    \"CV F1-macro (Â±2Ïƒ)\": [v[\"cv_f1_macro_std\"] * 2 for v in results.values()],\n",
    "    \"ROC AUC (OVR, macro)\": [v[\"auc_macro_ovr\"] for v in results.values()],\n",
    "}).sort_values(\"CV F1-macro (mean)\", ascending=False)\n",
    "\n",
    "with pd.option_context(\"display.max_columns\", None, \"display.width\", 160):\n",
    "    print(\"\\n=== Model Comparison ===\")\n",
    "    print(comparison_df.round(4).to_string(index=False))\n",
    "\n",
    "best_model_name = comparison_df.iloc[0][\"Model\"]\n",
    "best_info = results[best_model_name]\n",
    "best_pipe = best_info[\"pipeline\"]\n",
    "\n",
    "print(f\"\\nðŸ† Best Model: {best_model_name}\")\n",
    "print(f\"   CV F1-macro (mean): {best_info['cv_f1_macro']:.4f}\")\n",
    "print(f\"   Test Accuracy      : {best_info['accuracy']:.4f}\")\n",
    "print(f\"   ROC AUC (OVR, macro): {best_info['auc_macro_ovr'] if best_info['auc_macro_ovr'] is not None else 'N/A'}\")\n",
    "\n",
    "# Detailed report & confusion matrix for best\n",
    "y_pred_best = best_pipe.predict(X_test)\n",
    "print(f\"\\nDetailed Classification Report for {best_model_name}:\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=LABEL_SET))\n",
    "\n",
    "cm_best = confusion_matrix(y_test, y_pred_best)\n",
    "plot_confusion_matrix(cm_best, LABEL_SET, f\"Confusion Matrix â€” {best_model_name}\",\n",
    "                      save_path=os.path.join(LOG_DIR, f\"cm_{best_model_name}.png\"))\n",
    "\n",
    "#%% [Block 10: Grid Search on the Best Pipeline]\n",
    "log.info(\"Block 10: Model Optimization via GridSearchCV (%s)\", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-02 17:08:23,983 | INFO | Block 10: Model Optimization via GridSearchCV (XGBoost)\n",
      "2025-10-02 17:08:23,987 | INFO | Tuning params: {\n",
      "  \"sel__k\": [\n",
      "    20,\n",
      "    30,\n",
      "    38\n",
      "  ],\n",
      "  \"clf__n_estimators\": [\n",
      "    300,\n",
      "    500\n",
      "  ],\n",
      "  \"clf__learning_rate\": [\n",
      "    0.05,\n",
      "    0.1\n",
      "  ],\n",
      "  \"clf__max_depth\": [\n",
      "    4,\n",
      "    6\n",
      "  ],\n",
      "  \"clf__subsample\": [\n",
      "    0.8,\n",
      "    1.0\n",
      "  ],\n",
      "  \"clf__colsample_bytree\": [\n",
      "    0.8,\n",
      "    1.0\n",
      "  ]\n",
      "}\n",
      "2025-10-02 17:08:24,014 | INFO | SelectKBest | Transformed features=39 | Using k=39\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "2025-10-02 17:14:44,531 | INFO | Grid Search complete. Best params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.1, 'clf__max_depth': 6, 'clf__n_estimators': 300, 'clf__subsample': 1.0, 'sel__k': 38}\n",
      "2025-10-02 17:14:44,533 | INFO | Best CV F1-macro: 0.8904\n",
      "\n",
      "=== Optimized Model â€” Test ===\n",
      " Accuracy  : 0.9625\n",
      " F1-macro  : 0.8736\n",
      " ROC AUC   : 0.9885637087658236\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% [Block 10: Grid Search on the Best Pipeline]\n",
    "log.info(\"Block 10: Model Optimization via GridSearchCV (%s)\", best_model_name)\n",
    "\n",
    "# Rebuild a fresh pipe with a fresh selector (so GridSearch can change k reliably)\n",
    "def rebuild_best_pipe(name):\n",
    "    base = None\n",
    "    if name == \"Random Forest\":\n",
    "        base = RandomForestClassifier(\n",
    "            n_estimators=500, random_state=RANDOM_STATE, n_jobs=-1,\n",
    "            class_weight=\"balanced_subsample\"\n",
    "        )\n",
    "    elif name == \"Gradient Boosting\":\n",
    "        base = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "    elif name == \"Logistic Regression\":\n",
    "        base = LogisticRegression(\n",
    "            random_state=RANDOM_STATE, max_iter=4000,\n",
    "            class_weight=class_weight, multi_class=\"auto\", solver=\"lbfgs\"\n",
    "        )\n",
    "    elif name == \"SVM\":\n",
    "        base = SVC(\n",
    "            random_state=RANDOM_STATE, probability=True,\n",
    "            class_weight=class_weight, kernel=\"rbf\", gamma=\"scale\"\n",
    "        )\n",
    "    elif name == \"XGBoost\" and HAS_XGB:\n",
    "        base = XGBClassifier(\n",
    "            random_state=RANDOM_STATE, n_estimators=600, learning_rate=0.05, max_depth=6,\n",
    "            subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,\n",
    "            objective=\"multi:softprob\", eval_metric=\"mlogloss\", n_jobs=-1\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown/unsupported model for rebuild: {name}\")\n",
    "\n",
    "    # fresh selector; k will be replaced by GridSearch param\n",
    "    sel = make_select_k(SELECT_K, preproc, X_train)\n",
    "    return Pipeline([(\"pre\", preproc), (\"sel\", sel), (\"clf\", base)])\n",
    "\n",
    "base_param_grid = {\n",
    "    \"sel__k\": [\n",
    "        min(20, X_train.shape[1]),\n",
    "        min(30, X_train.shape[1]),\n",
    "        min(40, X_train.shape[1])\n",
    "    ]\n",
    "}\n",
    "\n",
    "if best_model_name == \"Random Forest\":\n",
    "    param_grid = {\n",
    "        **base_param_grid,\n",
    "        \"clf__n_estimators\": [300, 500],\n",
    "        \"clf__max_depth\": [None, 10, 20],\n",
    "        \"clf__min_samples_split\": [2, 5],\n",
    "        \"clf__min_samples_leaf\": [1, 2],\n",
    "    }\n",
    "elif best_model_name == \"Gradient Boosting\":\n",
    "    param_grid = {\n",
    "        **base_param_grid,\n",
    "        \"clf__n_estimators\": [200, 400],\n",
    "        \"clf__learning_rate\": [0.05, 0.1],\n",
    "        \"clf__max_depth\": [3, 5],\n",
    "    }\n",
    "elif best_model_name == \"Logistic Regression\":\n",
    "    param_grid = {\n",
    "        **base_param_grid,\n",
    "        \"clf__C\": [0.1, 1, 10],\n",
    "        \"clf__penalty\": [\"l2\"],\n",
    "    }\n",
    "elif best_model_name == \"SVM\":\n",
    "    param_grid = {\n",
    "        **base_param_grid,\n",
    "        \"clf__C\": [0.5, 1, 5],\n",
    "        \"clf__kernel\": [\"rbf\", \"poly\"],\n",
    "        \"clf__gamma\": [\"scale\", \"auto\"],\n",
    "    }\n",
    "elif best_model_name == \"XGBoost\" and HAS_XGB:\n",
    "    param_grid = {\n",
    "        **base_param_grid,\n",
    "        \"clf__n_estimators\": [300, 500],\n",
    "        \"clf__learning_rate\": [0.05, 0.1],\n",
    "        \"clf__max_depth\": [4, 6],\n",
    "        \"clf__subsample\": [0.8, 1.0],\n",
    "        \"clf__colsample_bytree\": [0.8, 1.0],\n",
    "    }\n",
    "else:\n",
    "    param_grid = base_param_grid\n",
    "\n",
    "log.info(\"Tuning params: %s\", json.dumps(param_grid, indent=2))\n",
    "\n",
    "opt_search = GridSearchCV(\n",
    "    estimator=rebuild_best_pipe(best_model_name),\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=gkf.split(X_train, y_train, groups=groups_train),\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "opt_search.fit(X_train, y_train)\n",
    "log.info(\"Grid Search complete. Best params: %s\", opt_search.best_params_)\n",
    "log.info(\"Best CV F1-macro: %.4f\", opt_search.best_score_)\n",
    "\n",
    "opt_pipe = opt_search.best_estimator_\n",
    "\n",
    "# Evaluate optimized pipeline on test\n",
    "y_pred_opt = opt_pipe.predict(X_test)\n",
    "\n",
    "opt_auc = np.nan\n",
    "try:\n",
    "    if hasattr(opt_pipe, \"predict_proba\"):\n",
    "        p = opt_pipe.predict_proba(X_test)\n",
    "        if isinstance(p, np.ndarray) and p.ndim == 2:\n",
    "            opt_auc = roc_auc_score(y_test, p, multi_class=\"ovr\", average=\"macro\")\n",
    "    elif hasattr(opt_pipe, \"decision_function\"):\n",
    "        s = opt_pipe.decision_function(X_test)\n",
    "        if isinstance(s, np.ndarray) and s.ndim == 2:\n",
    "            opt_auc = roc_auc_score(y_test, s, multi_class=\"ovr\", average=\"macro\")\n",
    "except Exception as e:\n",
    "    log.warning(\"AUC for optimized model failed: %s\", e)\n",
    "\n",
    "opt_acc = float((y_pred_opt == y_test).mean())\n",
    "opt_f1m = float(f1_score(y_test, y_pred_opt, average=\"macro\"))\n",
    "\n",
    "print(\"\\n=== Optimized Model â€” Test ===\")\n",
    "print(f\" Accuracy  : {opt_acc:.4f}\")\n",
    "print(f\" F1-macro  : {opt_f1m:.4f}\")\n",
    "print(f\" ROC AUC   : {opt_auc if not np.isnan(opt_auc) else 'N/A'}\")\n",
    "\n",
    "cm_opt = confusion_matrix(y_test, y_pred_opt)\n",
    "plot_confusion_matrix(cm_opt, LABEL_SET, f\"Confusion Matrix â€” {best_model_name} (Optimized)\",\n",
    "                      save_path=os.path.join(LOG_DIR, f\"cm_{best_model_name}_optimized.png\"))\n",
    "\n",
    "# Selected features after SelectKBest\n",
    "try:\n",
    "    # resolve feature names after preprocessing\n",
    "    # Fit preproc on all train to get OHE categories and names\n",
    "    preproc_fitted = opt_pipe.named_steps[\"pre\"]\n",
    "    if not hasattr(preproc_fitted, \"transformers_\"):\n",
    "        preproc_fitted.fit(X_train)\n",
    "\n",
    "    feature_names_pre = []\n",
    "    # numeric names\n",
    "    feature_names_pre.extend(list(preproc_fitted.transformers_[0][2]))  # from numeric_features\n",
    "    # categorical names via OHE\n",
    "    if len(categorical_features) > 0:\n",
    "        ohe = preproc_fitted.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "        cat_expanded = ohe.get_feature_names_out(categorical_features).tolist()\n",
    "        feature_names_pre.extend(cat_expanded)\n",
    "\n",
    "    selector = opt_pipe.named_steps[\"sel\"]\n",
    "    if hasattr(selector, \"get_support\"):\n",
    "        mask = selector.get_support()\n",
    "        selected_feature_names = [f for f, m in zip(feature_names_pre, mask) if m]\n",
    "    else:\n",
    "        selected_feature_names = feature_names_pre\n",
    "except Exception as e:\n",
    "    log.warning(\"Failed to retrieve selected feature names: %s\", e)\n",
    "    selected_feature_names = numeric_features + categorical_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0be73de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved:\n",
      "  â€¢ Pipeline : ml_artifacts\\k2_best_traditional_XGBoost.joblib\n",
      "  â€¢ Features : ml_artifacts\\selected_features.json\n",
      "  â€¢ Metadata : ml_artifacts\\metadata.json\n",
      "  â€¢ Logs     : ml_artifacts\\k2_train_20251002-170546.log\n"
     ]
    }
   ],
   "source": [
    "#%% [Block 11: Save Artifacts & Metadata]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "pipeline_path = os.path.join(LOG_DIR, f\"k2_best_traditional_{best_model_name}.joblib\")\n",
    "joblib.dump(opt_pipe, pipeline_path)\n",
    "\n",
    "feat_path = os.path.join(LOG_DIR, f\"selected_features.json\")\n",
    "with open(feat_path, \"w\") as f:\n",
    "    json.dump(selected_feature_names, f, indent=2)\n",
    "\n",
    "# Compile results (metrics only) minus actual pipeline objects\n",
    "results_metrics_only = {}\n",
    "for model_name, info in results.items():\n",
    "    metrics = {k: v for k, v in info.items() if k != \"pipeline\"}\n",
    "    results_metrics_only[model_name] = json_safe(metrics)\n",
    "\n",
    "meta = {\n",
    "    \"best_model\": best_model_name,\n",
    "    \"label_set\": json_safe(opt_search.best_params_),\n",
    "    \"cv_f1_macro\": float(opt_search.best_score_),\n",
    "    \"test_accuracy\": float(opt_acc),\n",
    "    \"test_f1_macro\": float(opt_f1m),\n",
    "    \"test_auc_ovr_macro\": None if np.isnan(opt_auc) else float(opt_auc),\n",
    "    \"n_selected_features\": len(selected_feature_names),\n",
    "    \"label_set\": LABEL_SET,\n",
    "    \"numeric_features\": numeric_features,\n",
    "    \"categorical_features\": categorical_features,\n",
    "    \"results_by_model\": results_metrics_only,\n",
    "    \"created_at\": timestamp,\n",
    "}\n",
    "meta_path = os.path.join(LOG_DIR, f\"metadata.json\")\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\"  â€¢ Pipeline :\", pipeline_path)\n",
    "print(\"  â€¢ Features :\", feat_path)\n",
    "print(\"  â€¢ Metadata :\", meta_path)\n",
    "print(\"  â€¢ Logs     :\", logfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef3d350",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18a02f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading pipeline: ml_artifacts\\k2_best_traditional_XGBoost.joblib\n"
     ]
    }
   ],
   "source": [
    "# === K2 Traditional ML â€” Jupyter prediction cell (row-selectable or full CSV) ===\n",
    "# Prereqs: you already ran train_k2_traditional_ml.py and have:\n",
    "#   ml_artifacts/metadata.json\n",
    "#   ml_artifacts/k2_best_traditional_<BestName>.joblib\n",
    "#\n",
    "# How to use:\n",
    "#   1) Set CSV_PATH as needed (the file you want to score).\n",
    "#   2) Run this cell.\n",
    "#   3) Examples:\n",
    "#        df_sel = predict_rows([1,2,3,4,5], save_path=\"ml_row_preds.csv\")\n",
    "#        df_all = predict_csv(save_path=\"ml_full_preds.csv\")\n",
    "\n",
    "import os, json, math, warnings\n",
    "from typing import List, Dict, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --------- User config ----------\n",
    "CSV_PATH = r\"E:\\Nasa Space App 2025\\Hunting_For_Exoplanets_With_AI_Nasa2025\\DataSet\\K2\\fast_100_rows.csv\"\n",
    "ART_DIR  = \"ml_artifacts\"   # where metadata.json + joblib live\n",
    "# --------------------------------\n",
    "\n",
    "# ---------- Utils (match training) ----------\n",
    "def add_k2_features(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = frame.copy()\n",
    "    if {\"pl_rade\",\"pl_radj\"}.issubset(out.columns):\n",
    "        denom = (out[\"pl_radj\"] * 11.209).replace(0, np.nan)\n",
    "        out[\"radius_consistency\"] = out[\"pl_rade\"] / denom\n",
    "    if {\"pl_bmasse\",\"pl_rade\"}.issubset(out.columns):\n",
    "        denom = (out[\"pl_rade\"]**3).replace(0, np.nan)\n",
    "        out[\"bulk_density_proxy\"] = out[\"pl_bmasse\"] / denom\n",
    "    if {\"pl_orbper\",\"pl_orbsmax\"}.issubset(out.columns):\n",
    "        denom = (out[\"pl_orbsmax\"]**3).replace(0, np.nan)\n",
    "        out[\"kepler_ratio\"] = (out[\"pl_orbper\"]**2) / denom\n",
    "    if {\"pl_eqt\",\"st_teff\"}.issubset(out.columns):\n",
    "        denom = out[\"st_teff\"].replace(0, np.nan)\n",
    "        out[\"temp_ratio\"] = out[\"pl_eqt\"] / denom\n",
    "    if \"pl_insol\" in out.columns:\n",
    "        out[\"log_insol\"] = np.log10(out[\"pl_insol\"].clip(lower=0) + 1)\n",
    "    if {\"st_mass\",\"st_rad\"}.issubset(out.columns):\n",
    "        denom = (out[\"st_rad\"]**3).replace(0, np.nan)\n",
    "        out[\"stellar_density_proxy\"] = out[\"st_mass\"] / denom\n",
    "    if \"sy_dist\" in out.columns:\n",
    "        out[\"log_distance\"] = np.log10(out[\"sy_dist\"].clip(lower=0) + 1)\n",
    "    if \"pl_orbper\" in out.columns:\n",
    "        out[\"log_period\"] = np.log10(out[\"pl_orbper\"].clip(lower=0) + 1)\n",
    "    return out.replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "def choose_id_columns(df: pd.DataFrame) -> List[str]:\n",
    "    candidates = [\n",
    "        \"kepid\",\"koi_name\",\"koi_disposition\",\n",
    "        \"epic\",\"epicid\",\"epic_name\",\"pl_name\",\n",
    "        \"hostname\",\"tic_id\",\"ticid\",\"rowid\"\n",
    "    ]\n",
    "    return [c for c in candidates if c in df.columns]\n",
    "\n",
    "# ---------- Load artifacts ----------\n",
    "meta_path = os.path.join(ART_DIR, \"metadata.json\")\n",
    "if not os.path.exists(meta_path):\n",
    "    raise FileNotFoundError(f\"Missing metadata.json in {ART_DIR}\")\n",
    "with open(meta_path, \"r\") as f:\n",
    "    META = json.load(f)\n",
    "\n",
    "LABEL_SET: List[str] = META[\"label_set\"]\n",
    "NUMERIC_FEATURES: List[str] = META[\"numeric_features\"]\n",
    "CATEGORICAL_FEATURES: List[str] = META[\"categorical_features\"]\n",
    "BEST_NAME: str = META[\"best_model\"]\n",
    "\n",
    "joblib_path_guess = os.path.join(ART_DIR, f\"k2_best_traditional_{BEST_NAME}.joblib\")\n",
    "if not os.path.exists(joblib_path_guess):\n",
    "    # fallback: pick any .joblib if naming changed\n",
    "    cands = [os.path.join(ART_DIR, f) for f in os.listdir(ART_DIR) if f.endswith(\".joblib\")]\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(f\"No .joblib found in {ART_DIR}\")\n",
    "    joblib_path = cands[0]\n",
    "else:\n",
    "    joblib_path = joblib_path_guess\n",
    "\n",
    "print(f\"ðŸ“¦ Loading pipeline: {joblib_path}\")\n",
    "PIPE = joblib.load(joblib_path)\n",
    "\n",
    "# ---------- Load CSV once ----------\n",
    "FULL_DF = pd.read_csv(CSV_PATH, low_memory=False)\n",
    "\n",
    "# ---------- Core predictor helpers ----------\n",
    "def _prepare_features(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add engineered features and select only the columns the pipeline expects.\"\"\"\n",
    "    df_feat = add_k2_features(df_in.copy())\n",
    "    # Ensure all expected columns exist\n",
    "    for c in NUMERIC_FEATURES + CATEGORICAL_FEATURES:\n",
    "        if c not in df_feat.columns:\n",
    "            # numeric missing -> NaN; categorical missing -> \"UNK\"\n",
    "            df_feat[c] = np.nan if c in NUMERIC_FEATURES else \"UNK\"\n",
    "    # Keep only expected columns in proper order\n",
    "    df_feat = df_feat[NUMERIC_FEATURES + CATEGORICAL_FEATURES]\n",
    "    return df_feat\n",
    "\n",
    "def _predict_df(df_in: pd.DataFrame, batch_size: Optional[int] = None):\n",
    "    X = _prepare_features(df_in)\n",
    "    # Predictions\n",
    "    y_idx = PIPE.predict(X)\n",
    "    # Probabilities (if available)\n",
    "    proba = None\n",
    "    if hasattr(PIPE, \"predict_proba\"):\n",
    "        try:\n",
    "            proba = PIPE.predict_proba(X)\n",
    "        except Exception:\n",
    "            proba = None\n",
    "    # Map to labels\n",
    "    y_lab = [LABEL_SET[i] for i in y_idx]\n",
    "    return y_idx, y_lab, proba\n",
    "\n",
    "def predict_rows(rows_1based: List[int], save_path: Optional[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"Predict for specific 1-based row numbers from FULL_DF.\"\"\"\n",
    "    if not rows_1based:\n",
    "        raise ValueError(\"Provide at least one row number (1-based).\")\n",
    "    idx0 = [r-1 for r in rows_1based]\n",
    "    max_i = len(FULL_DF) - 1\n",
    "    bad = [i for i in idx0 if i < 0 or i > max_i]\n",
    "    if bad:\n",
    "        raise IndexError(f\"Row(s) out of range 0..{max_i} (zero-based): {bad} (remember you pass 1-based)\")\n",
    "\n",
    "    df_sel = FULL_DF.iloc[idx0].copy()\n",
    "    y_idx, y_lab, proba = _predict_df(df_sel)\n",
    "\n",
    "    # Build output\n",
    "    id_cols = choose_id_columns(df_sel)\n",
    "    out = pd.DataFrame(index=df_sel.index)\n",
    "    if id_cols:\n",
    "        out[id_cols] = df_sel[id_cols]\n",
    "    out[\"row_number_1based\"] = out.index + 1\n",
    "    out[\"pred_index\"] = y_idx\n",
    "    out[\"pred_label\"] = y_lab\n",
    "\n",
    "    if isinstance(proba, np.ndarray) and proba.ndim == 2 and proba.shape[1] == len(LABEL_SET):\n",
    "        for i, lab in enumerate(LABEL_SET):\n",
    "            out[f\"prob_{lab.replace(' ','_').lower()}\"] = proba[:, i]\n",
    "        out[\"pred_confidence\"] = out[[f\"prob_{lab.replace(' ','_').lower()}\" for lab in LABEL_SET]].max(axis=1)\n",
    "\n",
    "    # Nicely ordered columns\n",
    "    front = (id_cols + [\"row_number_1based\",\"pred_label\",\"pred_index\"])\n",
    "    if \"pred_confidence\" in out.columns:\n",
    "        front += [\"pred_confidence\"]\n",
    "    rest = [c for c in out.columns if c not in front]\n",
    "    out = out[front + rest]\n",
    "\n",
    "    if save_path:\n",
    "        out.to_csv(save_path, index=False)\n",
    "        print(f\"âœ… Saved predictions for rows {rows_1based} â†’ {save_path}\")\n",
    "\n",
    "    # Preview\n",
    "    show_cols = [c for c in [\"row_number_1based\"] + id_cols + [\"pred_label\",\"pred_confidence\"] if c in out.columns]\n",
    "    print(out[show_cols].to_string(index=False))\n",
    "    return out\n",
    "\n",
    "def predict_csv(in_csv: Optional[str] = None, save_path: Optional[str] = None, chunk_size: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predict for an entire CSV (defaulting to CSV_PATH).\n",
    "    Optionally stream in chunks to reduce memory (no shuffling; concatenates outputs).\n",
    "    \"\"\"\n",
    "    path = in_csv or CSV_PATH\n",
    "    if chunk_size is None:\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "        y_idx, y_lab, proba = _predict_df(df)\n",
    "\n",
    "        id_cols = choose_id_columns(df)\n",
    "        out = pd.DataFrame(index=df.index)\n",
    "        if id_cols:\n",
    "            out[id_cols] = df[id_cols]\n",
    "        out[\"row_number_1based\"] = out.index + 1\n",
    "        out[\"pred_index\"] = y_idx\n",
    "        out[\"pred_label\"] = y_lab\n",
    "\n",
    "        if isinstance(proba, np.ndarray) and proba.ndim == 2 and proba.shape[1] == len(LABEL_SET):\n",
    "            for i, lab in enumerate(LABEL_SET):\n",
    "                out[f\"prob_{lab.replace(' ','_').lower()}\"] = proba[:, i]\n",
    "            out[\"pred_confidence\"] = out[[f\"prob_{lab.replace(' ','_').lower()}\" for lab in LABEL_SET]].max(axis=1)\n",
    "\n",
    "        if save_path:\n",
    "            out.to_csv(save_path, index=False)\n",
    "            print(f\"âœ… Saved full predictions â†’ {save_path}\")\n",
    "\n",
    "        print(out[[c for c in [\"row_number_1based\"] + choose_id_columns(df) + [\"pred_label\",\"pred_confidence\"] if c in out.columns]].head(10).to_string(index=False))\n",
    "        return out\n",
    "    else:\n",
    "        # Chunked (memory-friendly)\n",
    "        outs = []\n",
    "        start_idx = 0\n",
    "        for chunk in pd.read_csv(path, low_memory=False, chunksize=chunk_size):\n",
    "            y_idx, y_lab, proba = _predict_df(chunk)\n",
    "            id_cols = choose_id_columns(chunk)\n",
    "            out = pd.DataFrame(index=range(start_idx, start_idx + len(chunk)))\n",
    "            if id_cols:\n",
    "                out[id_cols] = chunk[id_cols].values\n",
    "            out[\"row_number_1based\"] = out.index + 1\n",
    "            out[\"pred_index\"] = y_idx\n",
    "            out[\"pred_label\"] = y_lab\n",
    "            if isinstance(proba, np.ndarray) and proba.ndim == 2 and proba.shape[1] == len(LABEL_SET):\n",
    "                for i, lab in enumerate(LABEL_SET):\n",
    "                    out[f\"prob_{lab.replace(' ','_').lower()}\"] = proba[:, i]\n",
    "                out[\"pred_confidence\"] = out[[f\"prob_{lab.replace(' ','_').lower()}\" for lab in LABEL_SET]].max(axis=1)\n",
    "            outs.append(out)\n",
    "            start_idx += len(chunk)\n",
    "\n",
    "        out_all = pd.concat(outs, axis=0, ignore_index=True)\n",
    "        if save_path:\n",
    "            out_all.to_csv(save_path, index=False)\n",
    "            print(f\"âœ… Saved full predictions (chunked) â†’ {save_path}\")\n",
    "        print(out_all.head(10).to_string(index=False))\n",
    "        return out_all\n",
    "\n",
    "# ---- Examples (uncomment to run) ----\n",
    "# df_sel = predict_rows([1,2,3,4,5], save_path=\"ml_row_preds.csv\")\n",
    "# df_all = predict_csv(save_path=\"ml_full_preds.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " row_number_1based           pl_name       hostname     pred_label  pred_confidence\n",
      "                45 EPIC 201324549.01 EPIC 201324549 FALSE POSITIVE         0.996771\n",
      "                46 EPIC 201324549.01 EPIC 201324549 FALSE POSITIVE         0.996578\n",
      "                47 EPIC 201324549.01 EPIC 201324549 FALSE POSITIVE         0.999280\n",
      "                48 EPIC 201324549.01 EPIC 201324549 FALSE POSITIVE         0.990292\n",
      "                49 EPIC 201324549.01 EPIC 201324549 FALSE POSITIVE         0.991533\n",
      "                 1       BD+20 594 b      BD+20 594      CONFIRMED         0.999761\n",
      "                 2       BD+20 594 b      BD+20 594      CONFIRMED         0.999233\n",
      "                 3       BD+20 594 b      BD+20 594      CONFIRMED         0.982651\n",
      "                 4 EPIC 201111557.01 EPIC 201111557      CANDIDATE         0.998026\n",
      "                 5 EPIC 201111557.01 EPIC 201111557      CANDIDATE         0.989263\n",
      "                 6 EPIC 201126503.01 EPIC 201126503      CANDIDATE         0.995501\n",
      "                 7 EPIC 201127519.01 EPIC 201127519      CANDIDATE         0.993693\n",
      "                 8 EPIC 201127519.01 EPIC 201127519      CANDIDATE         0.974416\n",
      "                 9 EPIC 201147085.01 EPIC 201147085      CANDIDATE         0.997423\n",
      "                10 EPIC 201152065.01 EPIC 201152065      CANDIDATE         0.999855\n",
      "                11 EPIC 201160662.01 EPIC 201160662      CANDIDATE         0.987416\n",
      "                12 EPIC 201164625.01 EPIC 201164625      CANDIDATE         0.993283\n",
      "                13 EPIC 201166680.01         K2-243      CANDIDATE         0.948234\n",
      "                14 EPIC 201170410.02 EPIC 201170410      CONFIRMED         0.998923\n",
      "                97 EPIC 201577112.01 EPIC 201577112      CANDIDATE         0.996485\n",
      "                98 EPIC 201588420.01 EPIC 201588420      CANDIDATE         0.999303\n",
      "                99 EPIC 201588420.01 EPIC 201588420      CANDIDATE         0.999526\n",
      "               100  EPIC 201595106 b EPIC 201595106      CONFIRMED         0.999874\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl_name</th>\n",
       "      <th>hostname</th>\n",
       "      <th>row_number_1based</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_index</th>\n",
       "      <th>pred_confidence</th>\n",
       "      <th>prob_candidate</th>\n",
       "      <th>prob_confirmed</th>\n",
       "      <th>prob_false_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>EPIC 201324549.01</td>\n",
       "      <td>EPIC 201324549</td>\n",
       "      <td>45</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996771</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.996771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>EPIC 201324549.01</td>\n",
       "      <td>EPIC 201324549</td>\n",
       "      <td>46</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996578</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.996578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>EPIC 201324549.01</td>\n",
       "      <td>EPIC 201324549</td>\n",
       "      <td>47</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999280</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.999280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>EPIC 201324549.01</td>\n",
       "      <td>EPIC 201324549</td>\n",
       "      <td>48</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.990292</td>\n",
       "      <td>0.009438</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.990292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>EPIC 201324549.01</td>\n",
       "      <td>EPIC 201324549</td>\n",
       "      <td>49</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.991533</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.991533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BD+20 594 b</td>\n",
       "      <td>BD+20 594</td>\n",
       "      <td>1</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BD+20 594 b</td>\n",
       "      <td>BD+20 594</td>\n",
       "      <td>2</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BD+20 594 b</td>\n",
       "      <td>BD+20 594</td>\n",
       "      <td>3</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982651</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.982651</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPIC 201111557.01</td>\n",
       "      <td>EPIC 201111557</td>\n",
       "      <td>4</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998026</td>\n",
       "      <td>0.998026</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.001384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPIC 201111557.01</td>\n",
       "      <td>EPIC 201111557</td>\n",
       "      <td>5</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989263</td>\n",
       "      <td>0.989263</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EPIC 201126503.01</td>\n",
       "      <td>EPIC 201126503</td>\n",
       "      <td>6</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995501</td>\n",
       "      <td>0.995501</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.004430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EPIC 201127519.01</td>\n",
       "      <td>EPIC 201127519</td>\n",
       "      <td>7</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993693</td>\n",
       "      <td>0.993693</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.005246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EPIC 201127519.01</td>\n",
       "      <td>EPIC 201127519</td>\n",
       "      <td>8</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974416</td>\n",
       "      <td>0.974416</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.024534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EPIC 201147085.01</td>\n",
       "      <td>EPIC 201147085</td>\n",
       "      <td>9</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997423</td>\n",
       "      <td>0.997423</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.002478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EPIC 201152065.01</td>\n",
       "      <td>EPIC 201152065</td>\n",
       "      <td>10</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EPIC 201160662.01</td>\n",
       "      <td>EPIC 201160662</td>\n",
       "      <td>11</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987416</td>\n",
       "      <td>0.987416</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.012413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EPIC 201164625.01</td>\n",
       "      <td>EPIC 201164625</td>\n",
       "      <td>12</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993283</td>\n",
       "      <td>0.993283</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.006421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EPIC 201166680.01</td>\n",
       "      <td>K2-243</td>\n",
       "      <td>13</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948234</td>\n",
       "      <td>0.948234</td>\n",
       "      <td>0.051634</td>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EPIC 201170410.02</td>\n",
       "      <td>EPIC 201170410</td>\n",
       "      <td>14</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998923</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.998923</td>\n",
       "      <td>0.000319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>EPIC 201577112.01</td>\n",
       "      <td>EPIC 201577112</td>\n",
       "      <td>97</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996485</td>\n",
       "      <td>0.996485</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>EPIC 201588420.01</td>\n",
       "      <td>EPIC 201588420</td>\n",
       "      <td>98</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>EPIC 201588420.01</td>\n",
       "      <td>EPIC 201588420</td>\n",
       "      <td>99</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>EPIC 201595106 b</td>\n",
       "      <td>EPIC 201595106</td>\n",
       "      <td>100</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pl_name        hostname  row_number_1based      pred_label  \\\n",
       "44  EPIC 201324549.01  EPIC 201324549                 45  FALSE POSITIVE   \n",
       "45  EPIC 201324549.01  EPIC 201324549                 46  FALSE POSITIVE   \n",
       "46  EPIC 201324549.01  EPIC 201324549                 47  FALSE POSITIVE   \n",
       "47  EPIC 201324549.01  EPIC 201324549                 48  FALSE POSITIVE   \n",
       "48  EPIC 201324549.01  EPIC 201324549                 49  FALSE POSITIVE   \n",
       "0         BD+20 594 b       BD+20 594                  1       CONFIRMED   \n",
       "1         BD+20 594 b       BD+20 594                  2       CONFIRMED   \n",
       "2         BD+20 594 b       BD+20 594                  3       CONFIRMED   \n",
       "3   EPIC 201111557.01  EPIC 201111557                  4       CANDIDATE   \n",
       "4   EPIC 201111557.01  EPIC 201111557                  5       CANDIDATE   \n",
       "5   EPIC 201126503.01  EPIC 201126503                  6       CANDIDATE   \n",
       "6   EPIC 201127519.01  EPIC 201127519                  7       CANDIDATE   \n",
       "7   EPIC 201127519.01  EPIC 201127519                  8       CANDIDATE   \n",
       "8   EPIC 201147085.01  EPIC 201147085                  9       CANDIDATE   \n",
       "9   EPIC 201152065.01  EPIC 201152065                 10       CANDIDATE   \n",
       "10  EPIC 201160662.01  EPIC 201160662                 11       CANDIDATE   \n",
       "11  EPIC 201164625.01  EPIC 201164625                 12       CANDIDATE   \n",
       "12  EPIC 201166680.01          K2-243                 13       CANDIDATE   \n",
       "13  EPIC 201170410.02  EPIC 201170410                 14       CONFIRMED   \n",
       "96  EPIC 201577112.01  EPIC 201577112                 97       CANDIDATE   \n",
       "97  EPIC 201588420.01  EPIC 201588420                 98       CANDIDATE   \n",
       "98  EPIC 201588420.01  EPIC 201588420                 99       CANDIDATE   \n",
       "99   EPIC 201595106 b  EPIC 201595106                100       CONFIRMED   \n",
       "\n",
       "    pred_index  pred_confidence  prob_candidate  prob_confirmed  \\\n",
       "44           2         0.996771        0.003077        0.000152   \n",
       "45           2         0.996578        0.003272        0.000150   \n",
       "46           2         0.999280        0.000630        0.000091   \n",
       "47           2         0.990292        0.009438        0.000270   \n",
       "48           2         0.991533        0.008388        0.000079   \n",
       "0            1         0.999761        0.000230        0.999761   \n",
       "1            1         0.999233        0.000743        0.999233   \n",
       "2            1         0.982651        0.017045        0.982651   \n",
       "3            0         0.998026        0.998026        0.000590   \n",
       "4            0         0.989263        0.989263        0.001396   \n",
       "5            0         0.995501        0.995501        0.000069   \n",
       "6            0         0.993693        0.993693        0.001061   \n",
       "7            0         0.974416        0.974416        0.001050   \n",
       "8            0         0.997423        0.997423        0.000099   \n",
       "9            0         0.999855        0.999855        0.000021   \n",
       "10           0         0.987416        0.987416        0.000171   \n",
       "11           0         0.993283        0.993283        0.000296   \n",
       "12           0         0.948234        0.948234        0.051634   \n",
       "13           1         0.998923        0.000757        0.998923   \n",
       "96           0         0.996485        0.996485        0.000214   \n",
       "97           0         0.999303        0.999303        0.000090   \n",
       "98           0         0.999526        0.999526        0.000027   \n",
       "99           1         0.999874        0.000116        0.999874   \n",
       "\n",
       "    prob_false_positive  \n",
       "44             0.996771  \n",
       "45             0.996578  \n",
       "46             0.999280  \n",
       "47             0.990292  \n",
       "48             0.991533  \n",
       "0              0.000009  \n",
       "1              0.000024  \n",
       "2              0.000304  \n",
       "3              0.001384  \n",
       "4              0.009340  \n",
       "5              0.004430  \n",
       "6              0.005246  \n",
       "7              0.024534  \n",
       "8              0.002478  \n",
       "9              0.000124  \n",
       "10             0.012413  \n",
       "11             0.006421  \n",
       "12             0.000132  \n",
       "13             0.000319  \n",
       "96             0.003300  \n",
       "97             0.000608  \n",
       "98             0.000447  \n",
       "99             0.000010  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel = predict_rows([45,46,47,48,49,1,2,3,4,5,6,7,8,9,10,11,12,13,14,97,98,99,100])\n",
    "df_sel\n",
    "# df_all = predict_csv(save_path=\"ml_full_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
